"""Module to estimate embedded solar capacity for each transformer site.

Uses the pre-trained XGBoost model as a 'digital twin' to simulate power
demand under two opposing, artificial weather scenarios during midday hours.

  - Scenario A (Low Sun): Simulates an overcast day with effectively zero solar
    radiation and maximum cloud cover. The model's prediction under this
    scenario establishes a baseline power demand.

  - Scenario B (High Sun): Simulates a bright, clear day with very high
    solar radiation and minimal cloud cover. The model's prediction here
    represents power demand when local solar generation is at its peak.

The embedded capacity is then calculated as the difference between the power
predicted in Scenario A and Scenario B. This 'delta' hence represents the total
power being generated by unmetered solar panels within the network.
"""
import logging
from typing import Any

import numpy as np
import pandas as pd
import seaborn as sns
import xarray as xr
from matplotlib import dates as mdates
from matplotlib import pyplot as plt
from xgboost import XGBRegressor

from src.feature_engineering import (
    create_cyclical_features,
    create_event_features,
    create_lag_and_roll_features,
    create_power_weather_interactions,
    create_weather_enhancements,
    remove_constant_features,
)


def _define_extreme_scenarios(
    historical_weather_ds: xr.Dataset, config: dict[str, Any],
) -> dict[str, Any]:
    analysis_cfg = config["scenario_analysis_params"]
    data_cfg = config["data_ingestion_params"]

    midday_mask = (historical_weather_ds.time.dt.hour >= analysis_cfg["midday_start_hour"]) & (
        historical_weather_ds.time.dt.hour <= analysis_cfg["midday_end_hour"]
    )
    historical_midday = historical_weather_ds.where(midday_mask, drop=True)

    ssrd_var = data_cfg["weather_vars_map"]["ssrd"]
    tcc_var = data_cfg["weather_vars_map"]["tcc"]
    t2m_var = data_cfg["weather_vars_map"]["t2m"]
    skt_var = data_cfg["weather_vars_map"]["skt"]

    ssrd_high = historical_midday[ssrd_var].quantile(
        analysis_cfg["ssrd_high_percentile"] / 100.0,
    ).item()
    tcc_low = historical_midday[tcc_var].quantile(
        analysis_cfg["tcc_low_percentile"] / 100.0,
    ).item()

    t2m_high = historical_midday[t2m_var].quantile(
        analysis_cfg.get("temp_high_percentile", 95) / 100.0,
    ).item()
    t2m_low = historical_midday[t2m_var].quantile(
        analysis_cfg.get("temp_low_percentile", 5) / 100.0,
    ).item()

    skt_high = historical_midday[skt_var].quantile(
        analysis_cfg.get("temp_high_percentile", 95) / 100.0,
    ).item()
    skt_low = historical_midday[skt_var].quantile(
        analysis_cfg.get("temp_low_percentile", 5) / 100.0,
    ).item()

    scenarios = {
        "HighSun": {
            ssrd_var: ssrd_high,
            tcc_var: tcc_low,
            t2m_var: t2m_high,
            skt_var: skt_high,
        },
        "LowSun": {
            ssrd_var: 0.0,
            tcc_var: 1.0,
            t2m_var: t2m_low,
            skt_var: skt_low,
        },
        "Baseline": None,
    }

    logging.info(
        "Defined scenarios: HighSun SSRD=%.2f, TCC=%.2f, T2M=%.2f, SKT=%.2f",
        ssrd_high,
        tcc_low,
        t2m_high,
        skt_high,
    )

    return scenarios


def _create_features_for_scenario(
    df: pd.DataFrame, config: dict[str, Any],
) -> pd.DataFrame:
    feature_cfg = config["feature_params"]
    data_cfg = config["data_ingestion_params"]

    df = create_cyclical_features(df)
    df = create_event_features(df)
    df = create_lag_and_roll_features(
        df,
        data_cfg["era5_vars"],
        feature_cfg["base_weather_lags"],
        feature_cfg["base_weather_roll_windows"],
    )
    df = create_power_weather_interactions(
        df,
        feature_cfg["target_column"],
        feature_cfg["tcc_var_name"],
        feature_cfg["power_interaction_lags"],
        feature_cfg["power_interaction_roll_windows"],
        feature_cfg["interaction_weather_lags"],
    )
    df = create_weather_enhancements(df, data_cfg["weather_vars_map"])

    cols_to_drop = data_cfg["era5_vars"] + [feature_cfg["target_column"]]
    df_final = df.drop(
        columns=[col for col in cols_to_drop if col in df.columns], errors="ignore",
    )
    df_final = remove_constant_features(df_final)

    return df_final.dropna()


def _plot_scenario_results(
    df_results: pd.DataFrame, site_id: str, config: dict[str, Any],
) -> None:
    plot_cfg = config["plotting"]
    output_dir = plot_cfg.get("plot_output_dir", "output_plots")
    site_name = site_id.replace("_primary_11kv_t1", "").replace("_", " ").title()

    plt.style.use("seaborn-v0_8-whitegrid")
    fig, ax = plt.subplots(figsize=(18, 8))

    ax.plot(
        df_results.index, df_results["Actual"], label="Actual Power", color="black", zorder=5,
    )
    ax.plot(
        df_results.index,
        df_results["Predicted_Baseline"],
        label="Predicted (Baseline)",
        color="darkorange",
        linestyle="--",
    )
    ax.plot(
        df_results.index,
        df_results["Predicted_HighSun"],
        label="Predicted (High Sun Scenario)",
        color="deepskyblue",
    )
    ax.plot(
        df_results.index,
        df_results["Predicted_LowSun"],
        label="Predicted (Low Sun Scenario)",
        color="mediumseagreen",
    )

    ax.set_title(f"Simulated Scenarios for {site_name}", fontsize=20)
    ax.set_ylabel("Power (MW)", fontsize=16)
    ax.legend(loc="best", fontsize=12)

    ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))
    ax.xaxis.set_major_formatter(mdates.DateFormatter("%a %b %d"))
    plt.setp(ax.get_xticklabels(), rotation=0, ha="center")

    plt.tight_layout()
    save_path = f"{output_dir}/scenario_plot_{site_id}.png"
    plt.savefig(save_path)
    plt.close(fig)
    logging.info(f"Scenario plot saved to {save_path}")


def _process_single_site(
    site_data_sim_period: pd.DataFrame,
    model: XGBRegressor,
    config: dict[str, Any],
    sim_start: pd.Timestamp,
    sim_end: pd.Timestamp,
) -> pd.DataFrame:
    historical_weather_ds = site_data_sim_period.to_xarray()
    scenarios = _define_extreme_scenarios(historical_weather_ds, config)
    site_predictions = {}
    analysis_cfg = config["scenario_analysis_params"]
    feature_cfg = config["feature_params"]

    for name, mods in scenarios.items():
        scenario_data = site_data_sim_period.copy()
        if mods:
            midday_mask = (scenario_data.index.hour >= analysis_cfg["midday_start_hour"]) & (
                scenario_data.index.hour <= analysis_cfg["midday_end_hour"]
            )
            for var, val in mods.items():
                scenario_data[var] = np.where(midday_mask, val, scenario_data[var])

        df_features = _create_features_for_scenario(scenario_data, config)
        if df_features.empty:
            logging.warning(
                f"Feature engineering for scenario '{name}' resulted in empty data. Skipping.",
            )
            continue

        X_scenario = df_features.reindex(columns=model.feature_names_in_).fillna(0)
        y_pred = model.predict(X_scenario)

        pred_series = pd.Series(y_pred, index=X_scenario.index)
        site_predictions[f"Predicted_{name}"] = pred_series.loc[sim_start:sim_end]

    site_predictions["Actual"] = site_data_sim_period[
        feature_cfg["target_column"]
    ].loc[sim_start:sim_end]
    return pd.DataFrame(site_predictions)


def _calculate_and_log_capacity(
    all_sites_results: dict[str, pd.DataFrame], config: dict[str, Any],
) -> pd.DataFrame:
    analysis_cfg = config["scenario_analysis_params"]
    capacity_results = {}
    for site, res_df in all_sites_results.items():
        if "Predicted_LowSun" in res_df and "Predicted_HighSun" in res_df:
            start_hour, end_hour = (
                analysis_cfg["midday_start_hour"],
                analysis_cfg["midday_end_hour"],
            )
            midday_res = res_df.between_time(f"{start_hour}:00", f"{end_hour}:00")
            delta = midday_res["Predicted_LowSun"] - midday_res["Predicted_HighSun"]
            capacity_results[site] = np.maximum(0, delta).mean()

    df_solar_capacity = pd.DataFrame.from_dict(
        capacity_results, orient="index", columns=["Embedded_Solar_Capacity_MW"],
    ).sort_values(by="Embedded_Solar_Capacity_MW", ascending=False)

    logging.info("\n\n--- Embedded Solar Capacity (Midday Average) ---")
    logging.info("\n" + df_solar_capacity.to_string())
    mean_capacity = df_solar_capacity["Embedded_Solar_Capacity_MW"].mean()
    logging.info(
        f"\nOverall Average Embedded Solar Capacity: {mean_capacity:.3f} MW",
    )
    return df_solar_capacity


def plot_capacity_distribution(df_solar_capacity: pd.DataFrame, config: dict[str, Any]) -> None:
    """Plots and saves a histogram of the distribution of embedded solar capacity."""
    if df_solar_capacity.empty:
        logging.warning("Solar capacity DataFrame is empty - cannot plot distribution.")
        return

    plot_cfg = config["plotting"]
    output_dir = plot_cfg.get("plot_output_dir", "output_plots")

    plt.figure(figsize=(12, 7))
    sns.set_style("whitegrid")

    sns.histplot(data=df_solar_capacity, x="Embedded_Solar_Capacity_MW", kde=True, bins=8)

    plt.title("Distribution of Estimated Solar Capacity Across Sites", fontsize=18)
    plt.xlabel("Estimated Embedded Solar Capacity (MW)", fontsize=14)
    plt.ylabel("Number of Sites", fontsize=14)

    mean_val = df_solar_capacity["Embedded_Solar_Capacity_MW"].mean()
    median_val = df_solar_capacity["Embedded_Solar_Capacity_MW"].median()

    plt.axvline(mean_val, color="red", linestyle="--", label=f"Mean: {mean_val:.3f} MW")
    plt.axvline(median_val, color="green", linestyle=":", label=f"Median: {median_val:.3f} MW")
    plt.legend()
    plt.tight_layout()

    save_path = f"{output_dir}/capacity_distribution_plot.png"
    plt.savefig(save_path)
    plt.close()


def run_scenario_analysis(
    model: XGBRegressor, master_df: pd.DataFrame, config: dict[str, Any],
) -> pd.DataFrame:
    """Run the full scenario analysis and embedded capacity estimation pipeline.

    Args:
        model: The pre-trained XGBoost model object.
        master_df: DataFrame containing the preprocessed power and weather data.
        config: The project's configuration dictionary.

    Returns:
        A DataFrame containing the estimated embedded solar capacity for each site.
    """
    analysis_cfg = config["scenario_analysis_params"]
    all_sites_simulation_results = {}

    sim_start = pd.to_datetime(analysis_cfg["simulation_start_date"], utc=True)
    sim_end = pd.to_datetime(analysis_cfg["simulation_end_date"], utc=True)
    buffer_start = sim_start - pd.Timedelta(hours=analysis_cfg["look_back_buffer_hours"])

    for tx_id, site_group in master_df.groupby("tx_id"):
        site_data_sim_period = site_group.loc[buffer_start:sim_end].copy()

        if site_data_sim_period.empty:
            logging.warning(
                f"Not enough data for site {tx_id} in simulation period. Skipping.",
            )
            continue

        site_results_df = _process_single_site(
            site_data_sim_period, model, config, sim_start, sim_end,
        )
        all_sites_simulation_results[tx_id] = site_results_df

        if config["plotting"].get("save_plots", False):
            _plot_scenario_results(site_results_df, tx_id, config)

    df_solar_capacity = _calculate_and_log_capacity(all_sites_simulation_results, config)

    if config["plotting"].get("save_plots", False):
        plot_capacity_distribution(df_solar_capacity, config)

    return df_solar_capacity
